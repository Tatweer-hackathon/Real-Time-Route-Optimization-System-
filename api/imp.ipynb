{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d04944",
   "metadata": {},
   "source": [
    "# Real-Time Route Optimization System "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ff68b",
   "metadata": {},
   "source": [
    "## Key Steps\n",
    "1. **Kafka Producer**: Fetches traffic data and sends it to Kafka.\n",
    "2. **Kafka Consumer**: Processes traffic data and stores it in the database.\n",
    "3. **Route Optimization Engine**: Computes optimal routes and checks if they meet the threshold.\n",
    "4. **Backend API**: Serves optimized routes to the frontend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0156d5",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de236045",
   "metadata": {},
   "source": [
    "### Step 1: Kafka Producer\n",
    "The Kafka Producer fetches traffic data from the TomTom API and sends it to the Kafka topic `traffic_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051507b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Kafka configuration\n",
    "conf = {'bootstrap.servers': 'localhost:9092'}\n",
    "producer = Producer(conf)\n",
    "\n",
    "# TomTom API configuration\n",
    "TOMTOM_API_KEY = 'YOU_API_KEY'\n",
    "TOMTOM_API_URL = \"https://api.tomtom.com/traffic/services/4/flowSegmentData/relative0/10/json\"\n",
    "\n",
    "def fetch_traffic_data(lat, lon):\n",
    "    params = {\n",
    "        'point': f'{lat},{lon}',\n",
    "        'unit': 'KMPH',\n",
    "        'key': TOMTOM_API_KEY\n",
    "    }\n",
    "    response = requests.get(TOMTOM_API_URL, params=params)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()}')\n",
    "\n",
    "def produce_traffic_data():\n",
    "    # Example coordinates (update with your delivery points)\n",
    "    locations = [\n",
    "        (34.0195, -118.4912),  # Point A\n",
    "        (34.0250, -118.5000),  # Point B\n",
    "        (34.0300, -118.5100)   # Point C\n",
    "    ]\n",
    "    while True:\n",
    "        for lat, lon in locations:\n",
    "            data = fetch_traffic_data(lat, lon)\n",
    "            if data:\n",
    "                producer.produce(\n",
    "                    'traffic_updates',\n",
    "                    json.dumps(data),\n",
    "                    callback=delivery_report\n",
    "                )\n",
    "                producer.flush()\n",
    "        time.sleep(300)  # Fetch data every 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa7f4ca",
   "metadata": {},
   "source": [
    "### Step 2: Kafka Consumer\n",
    "The Kafka Consumer processes traffic data and stores it in the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Kafka Configuration\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'traffic_consumer_group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "# PostgreSQL Configuration\n",
    "conn = psycopg2.connect(\"dbname=logistics user=postgres password=postgres host=localhost\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "def process_traffic_data(data):\n",
    "    try:\n",
    "        segment_id = data.get('segment_id')\n",
    "        speed_kmh = data.get('speed_kmh')\n",
    "        coordinates = data.get('coordinates')\n",
    "\n",
    "        if not all([segment_id, speed_kmh, coordinates]):\n",
    "            print(\"Error: Missing required fields in data\")\n",
    "            return\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO realtime_traffic (segment_id, speed_kmh, coordinates)\n",
    "            VALUES (%s, %s, ST_SetSRID(ST_MakeLine(\n",
    "                ST_MakePoint(%s, %s),\n",
    "                ST_MakePoint(%s, %s)\n",
    "            ), 4326))\n",
    "            ON CONFLICT (segment_id) DO UPDATE\n",
    "            SET speed_kmh = EXCLUDED.speed_kmh,\n",
    "                coordinates = EXCLUDED.coordinates,\n",
    "                timestamp = CURRENT_TIMESTAMP\n",
    "        \"\"\", (\n",
    "            segment_id,\n",
    "            speed_kmh,\n",
    "            coordinates[0][0], coordinates[0][1],\n",
    "            coordinates[1][0], coordinates[1][1]\n",
    "        ))\n",
    "        conn.commit()\n",
    "        print(\"Data successfully processed and stored in the database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "\n",
    "consumer = Consumer(conf)\n",
    "consumer.subscribe(['traffic_updates'])\n",
    "\n",
    "while True:\n",
    "    msg = consumer.poll(1.0)\n",
    "    if msg is None:\n",
    "        continue\n",
    "    if msg.error():\n",
    "        print(f\"Error: {msg.error()}\")\n",
    "        continue\n",
    "    try:\n",
    "        data = json.loads(msg.value())\n",
    "        process_traffic_data(data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411029e",
   "metadata": {},
   "source": [
    "### Step 3: Route Optimization Engine\n",
    "The Route Optimization Engine computes optimal routes and checks if they meet the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a06ccf",
   "metadata": {},
   "source": [
    "example threshold : https://github.com/aurelio-labs/semantic-router/blob/main/docs/06-threshold-optimization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3edc06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import psycopg2\n",
    "\n",
    "def calculate_optimal_route(origin, destinations, threshold=0.1):\n",
    "    conn = psycopg2.connect(\"dbname=logistics user=postgres password=postgres host=localhost\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        WITH traffic_data AS (\n",
    "            SELECT \n",
    "                d1.point_id AS origin_id,\n",
    "                d2.point_id AS destination_id,\n",
    "                ST_Distance(d1.location, d2.location) AS distance,\n",
    "                COALESCE(rt.speed_kmh, hd.traffic_factor * 50) AS speed\n",
    "            FROM delivery_points d1\n",
    "            CROSS JOIN delivery_points d2\n",
    "            LEFT JOIN realtime_traffic rt ON ST_Intersects(\n",
    "                ST_MakeLine(d1.location::geometry, d2.location::geometry),\n",
    "                rt.coordinates::geometry\n",
    "            )\n",
    "            LEFT JOIN historical_deliveries hd ON hd.point_id = d2.point_id\n",
    "            WHERE d1.point_id = %s AND d2.point_id IN %s\n",
    "        )\n",
    "        SELECT origin_id, destination_id, distance / speed AS travel_time\n",
    "        FROM traffic_data\n",
    "    \"\"\", (origin, tuple(destinations)))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for origin_id, dest_id, travel_time in cur:\n",
    "        G.add_edge(origin_id, dest_id, weight=travel_time)\n",
    "\n",
    "    optimal_route = nx.shortest_path(G, source=origin, weight='weight')\n",
    "    current_route = get_current_route(origin)\n",
    "\n",
    "    if is_route_improved(optimal_route, current_route, threshold):\n",
    "        update_route_in_db(optimal_route)\n",
    "        return optimal_route\n",
    "    else:\n",
    "        return current_route\n",
    "\n",
    "def get_current_route(origin):\n",
    "    # Fetch the current route from the database\n",
    "    pass\n",
    "\n",
    "def is_route_improved(new_route, current_route, threshold):\n",
    "    # Compare the new route with the current route using the threshold\n",
    "    pass\n",
    "\n",
    "def update_route_in_db(route):\n",
    "    # Update the database with the new route\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e7cdf",
   "metadata": {},
   "source": [
    "### Step 4: Backend API\n",
    "The Backend API serves optimized routes to the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class RouteRequest(BaseModel):\n",
    "    origin: int\n",
    "    destinations: list[int]\n",
    "\n",
    "@app.post(\"/optimize\")\n",
    "async def optimize_route(request: RouteRequest):\n",
    "    try:\n",
    "        optimal_route = calculate_optimal_route(request.origin, request.destinations)\n",
    "        return {\n",
    "            \"optimal_route\": optimal_route,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fe4ff",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook provides a basic implementation of the real-time route optimization system. The threshold optimization mechanism ensures that routes are only updated when significant improvements are detected, making the system more efficient."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
